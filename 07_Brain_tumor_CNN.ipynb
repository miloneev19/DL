{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9GwjpJS1lTdT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.imageimport ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\n",
    "from keras.optimizers\n",
    "import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image # Import the image functio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uklexV8SnVgY"
   },
   "outputs": [],
   "source": [
    "# Set your dataset path\n",
    " dataset_path = 'C:\\\\Users\\\\sd616\\\\Downloads\\\\bt'\n",
    "# dataset_path = '/home/username/Downloads/archive 3/'  # Linux or Mac\n",
    " # Define image dimensions\n",
    " img_width, img_height = 150, 150\n",
    " # Create ImageDataGenerator for training and testing\n",
    " train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    " test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    " # Load training data\n",
    " train_data = train_datagen.flow_from_directory(\n",
    " os.path.join(dataset_path, 'training'),\n",
    " target_size=(img_width, img_height),\n",
    " batch_size=32,\n",
    " class_mode='categorical'\n",
    " )\n",
    " # Load testing data\n",
    " test_data = test_datagen.flow_from_directory(\n",
    " os.path.join(dataset_path, 'testing'),\n",
    " target_size=(img_width, img_height),\n",
    " batch_size=32,\n",
    " class_mode='categorical'\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " # Define the CNN model\n",
    " model = Sequential()\n",
    " # First convolutional layer\n",
    " model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3), activation='relu'))\n",
    " model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " # Second convolutional layer\n",
    " model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    " model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " # Third convolutional layer\n",
    " model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    " model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " # Flatten layer\n",
    " model.add(Flatten())\n",
    " # Fully connected layer\n",
    " model.add(Dense(128, activation='relu'))\n",
    " model.add(Dropout(0.5))  # Dropout to avoid overfitting\n",
    " # Output layer (4 classes for tumor types)\n",
    " model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tikXrZPkn_MF"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    " model.compile(optimizer='adam',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULcM7MJJoCJl"
   },
   "outputs": [],
   "source": [
    "# Train the model with automatic steps_per_epoch\n",
    " history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=test_data,\n",
    "    epochs=10  # You can adjust the number of epochs\n",
    " )\n",
    "\n",
    "# Evaluate the model on the test data\n",
    " test_loss, test_acc = model.evaluate(test_data)\n",
    " print(f\"Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSGWuWrFoEF_"
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    " predictions = model.predict(test_data)\n",
    " # Print the predicted class for the first batch of images\n",
    " predicted_classes = tf.argmax(predictions, axis=1)\n",
    " print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18dVaJepoGS4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " # Plot training & validation accuracy values\n",
    " plt.plot(history.history['accuracy'])\n",
    " plt.plot(history.history['val_accuracy'])\n",
    " plt.title('Model accuracy')\n",
    " plt.ylabel('Accuracy')\n",
    " plt.xlabel('Epoch')\n",
    " plt.legend(['Train', 'Validation'], loc='upper left')\n",
    " plt.show()\n",
    " # Plot training & validation loss values\n",
    " plt.plot(history.history['loss'])\n",
    " plt.plot(history.history['val_loss'])\n",
    " plt.title('Model loss')\n",
    " plt.ylabel('Loss')\n",
    " plt.xlabel('Epoch')\n",
    " plt.legend(['Train', 'Validation'], loc='upper left')\n",
    " plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EkVMPT7uoNa4"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, img_width, img_height):\n",
    " img = image.load_img(img_path, target_size=(img_width, img_height))  #\n",
    "img_array = image.img_to_array(img)  # Convert image to array\n",
    " img_array = np.expand_dims(img_array, axis=0)  # Add a batch dimension\n",
    " img_array /= 255.0  # Normalize the image\n",
    " return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5PsC_wlbopA2"
   },
   "outputs": [],
   "source": [
    "img_path = r'C:\\\\Users\\\\sd616\\\\Downloads\\\\bt\\\\Training\\\\meningioma_tumor\\m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0i60b8WeomYR"
   },
   "outputs": [],
   "source": [
    "preprocessed_img = preprocess_image(img_path, img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pO0ysK6roPsC"
   },
   "outputs": [],
   "source": [
    "img_path = r'C:\\\\Users\\\\sd616\\\\Downloads\\\\bt\\\\Training\\\\meningioma_tumor\\m3\n",
    "\n",
    " plt.imshow(image.load_img(img_path, target_size=(img_width, img_height)))\n",
    " plt.axis('off')  # Turn off axis\n",
    " plt.show()\n",
    " # Make predictions\n",
    " prediction = model.predict(preprocessed_img)\n",
    " # Get the predicted class index\n",
    " predicted_class = np.argmax(prediction, axis=1)\n",
    " # Class labels\n",
    " class_labels = ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor', 'no_t\n",
    " # Get the class label for the predicted class\n",
    " predicted_label = class_labels[predicted_class[0]]\n",
    " # Output the prediction\n",
    " print(f'The model predicts: {predicted_label}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
